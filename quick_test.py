# quick_test_fixed.py
"""
ë¯¸ì‹ì¶•êµ¬ ì˜ìƒ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ì—ëŸ¬ ìˆ˜ì • ë²„ì „)
RTX 3050 GPU ì‚¬ìš© ìµœì í™”
"""

import os
import sys
import cv2
import torch
import numpy as np
from ultralytics import YOLO
import supervision as sv
from datetime import datetime
import time

# OpenCV GUI ì—ëŸ¬ í•´ê²°
import matplotlib
matplotlib.use('Agg')

def check_environment():
    """í™˜ê²½ ì²´í¬"""
    print("="*60)
    print("ğŸ” í™˜ê²½ í™•ì¸")
    print("="*60)
    
    # GPU í™•ì¸
    if torch.cuda.is_available():
        print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
        print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸
    video_dir = "videos"
    if not os.path.exists(video_dir):
        os.makedirs(video_dir)
        print(f"ğŸ“ {video_dir} í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì˜ìƒì„ ë„£ì–´ì£¼ì„¸ìš”!")
        return False
    
    videos = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi', '.mov', '.MP4', '.AVI', '.MOV'))]
    if not videos:
        print(f"âŒ {video_dir} í´ë”ì— ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return False
    
    print(f"\nğŸ“¹ ë°œê²¬ëœ ì˜ìƒ: {len(videos)}ê°œ")
    
    # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
    for i, video in enumerate(videos[:10], 1):
        file_path = os.path.join(video_dir, video)
        size = os.path.getsize(file_path) / (1024*1024)  # MB
        print(f"   {i}. {video} ({size:.1f} MB)")
    
    if len(videos) > 10:
        print(f"   ... ê·¸ ì™¸ {len(videos)-10}ê°œ ë”")
    
    return videos

def quick_analysis(video_path, output_dir="output", show_preview=False):
    """ë¹ ë¥¸ ë¶„ì„ ì‹¤í–‰"""
    print(f"\nğŸˆ ë¶„ì„ ì‹œì‘: {video_path}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ëª¨ë¸ ë¡œë“œ (ê¸°ë³¸ YOLOv8 ì‚¬ìš©)
    print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = YOLO('yolov8x.pt')  # ë†’ì€ ì •í™•ë„
    
    # ë¹„ë””ì˜¤ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"\nğŸ“Š ë¹„ë””ì˜¤ ì •ë³´:")
    print(f"   í•´ìƒë„: {width}x{height}")
    print(f"   FPS: {fps}")
    print(f"   ì´ í”„ë ˆì„: {total_frames}")
    print(f"   ê¸¸ì´: {total_frames/fps:.1f}ì´ˆ")
    
    # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
    output_path = os.path.join(output_dir, f"analyzed_{timestamp}.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # ByteTrack ì´ˆê¸°í™”
    tracker = sv.ByteTrack(
        track_activation_threshold=0.25,
        lost_track_buffer=30,
        minimum_matching_threshold=0.8
    )
    
    # Annotators ì´ˆê¸°í™” (ìƒˆë¡œìš´ supervision ë²„ì „)
    box_annotator = sv.BoxAnnotator(thickness=2, color=sv.ColorPalette.DEFAULT)
    label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=1)
    
    # í•„ë“œ ê²€ì¶œìš© ë³€ìˆ˜
    field_mask = None
    
    # í†µê³„
    stats = {
        'total_people': set(),
        'max_people_frame': 0,
        'max_people_count': 0,
        'frame_data': []
    }
    
    print("\nğŸ¬ ì²˜ë¦¬ ì¤‘...")
    
    frame_count = 0
    start_time = time.time()
    
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # YOLO ê²€ì¶œ (GPU ì‚¬ìš©)
            results = model(frame, device=0, conf=0.3, classes=[0], verbose=False)  # person í´ë˜ìŠ¤ë§Œ
            
            # Supervision í˜•ì‹ ë³€í™˜
            detections = sv.Detections.from_ultralytics(results[0])
            
            # í•„ë“œ ì˜ì—­ ê²€ì¶œ (ì²« í”„ë ˆì„)
            if frame_count == 0 and len(detections) > 0:
                # ê°„ë‹¨í•œ í•„ë“œ ê²€ì¶œ (ì”ë”” ìƒ‰ìƒ)
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                lower_green = np.array([35, 40, 40])
                upper_green = np.array([85, 255, 255])
                field_mask = cv2.inRange(hsv, lower_green, upper_green)
                
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel = np.ones((5,5), np.uint8)
                field_mask = cv2.morphologyEx(field_mask, cv2.MORPH_CLOSE, kernel)
            
            # í•„ë“œ ë‚´ë¶€ ì„ ìˆ˜ë§Œ í•„í„°ë§
            if field_mask is not None and len(detections) > 0:
                filtered = []
                for i, bbox in enumerate(detections.xyxy):
                    x1, y1, x2, y2 = bbox
                    foot_x = int((x1 + x2) / 2)
                    foot_y = int(y2)  # ë°œ ìœ„ì¹˜
                    
                    if 0 <= foot_y < field_mask.shape[0] and \
                       0 <= foot_x < field_mask.shape[1]:
                        if field_mask[foot_y, foot_x] > 0:
                            filtered.append(i)
                
                if filtered:
                    detections = detections[filtered]
            
            # ì¶”ì 
            detections = tracker.update_with_detections(detections)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if len(detections) > 0:
                for track_id in detections.tracker_id:
                    stats['total_people'].add(track_id)
                
                if len(detections) > stats['max_people_count']:
                    stats['max_people_count'] = len(detections)
                    stats['max_people_frame'] = frame_count
            
            # í”„ë ˆì„ë³„ ë°ì´í„° ì €ì¥
            stats['frame_data'].append({
                'frame': frame_count,
                'detected': len(detections),
                'ids': list(detections.tracker_id) if len(detections) > 0 else []
            })
            
            # ì‹œê°í™”
            annotated_frame = frame.copy()
            
            # ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë¼ë²¨ ê·¸ë¦¬ê¸°
            if len(detections) > 0:
                # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                annotated_frame = box_annotator.annotate(annotated_frame, detections)
                
                # ID ë¼ë²¨
                labels = [f"Player #{int(tid)}" for tid in detections.tracker_id]
                annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)
            
            # ì •ë³´ í‘œì‹œ
            info = [
                f"Frame: {frame_count}/{total_frames}",
                f"Detected: {len(detections)}",
                f"Total Tracked: {len(stats['total_people'])}"
            ]
            
            y_offset = 30
            for text in info:
                cv2.putText(annotated_frame, text, (10, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                y_offset += 25
            
            # ë¹„ë””ì˜¤ ì €ì¥
            out.write(annotated_frame)
            
            # ë¯¸ë¦¬ë³´ê¸° (ì˜µì…˜ - OpenCV GUI ë¬¸ì œë¡œ ê¸°ë³¸ ë¹„í™œì„±í™”)
            if show_preview:
                try:
                    preview = cv2.resize(annotated_frame, (1280, 720))
                    cv2.imshow('Football Analysis', preview)
                    
                    if cv2.waitKey(1) & 0xFF == 27:  # ESC
                        print("\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                        break
                except:
                    show_preview = False  # GUI ì—ëŸ¬ì‹œ ë¹„í™œì„±í™”
            
            # ì§„í–‰ ìƒí™©
            frame_count += 1
            if frame_count % 30 == 0:
                elapsed = time.time() - start_time
                fps_current = frame_count / elapsed
                eta = (total_frames - frame_count) / fps_current if fps_current > 0 else 0
                print(f"   {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%) - "
                      f"FPS: {fps_current:.1f} - ETA: {eta:.0f}ì´ˆ")
    
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
    
    finally:
        cap.release()
        out.release()
        try:
            cv2.destroyAllWindows()
        except:
            pass  # OpenCV GUI ì—ëŸ¬ ë¬´ì‹œ
    
    # ê²°ê³¼ ì¶œë ¥
    total_time = time.time() - start_time
    print("\n" + "="*60)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*60)
    print(f"ğŸ“Š ê²°ê³¼:")
    print(f"   ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")
    print(f"   í‰ê·  FPS: {frame_count/total_time:.1f}")
    print(f"   ì¶”ì ëœ ì´ ì¸ì›: {len(stats['total_people'])}ëª…")
    print(f"   ìµœëŒ€ ë™ì‹œ ê°ì§€: {stats['max_people_count']}ëª… (í”„ë ˆì„ {stats['max_people_frame']})")
    print(f"\nğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
    
    # CSVë¡œ í†µê³„ ì €ì¥
    import pandas as pd
    df = pd.DataFrame(stats['frame_data'])
    csv_path = output_path.replace('.mp4', '_stats.csv')
    df.to_csv(csv_path, index=False)
    print(f"ğŸ“Š í†µê³„ íŒŒì¼: {csv_path}")
    
    return output_path

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*60)
    print("ğŸˆ ë¯¸ì‹ì¶•êµ¬ ì˜ìƒ ë¶„ì„ - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # í™˜ê²½ í™•ì¸
    videos = check_environment()
    if not videos:
        return
    
    # ì˜ìƒ ì„ íƒ
    print("\nğŸ“Œ ì¶”ì²œ ì˜ìƒ (ì§§ì€ ê²ƒë¶€í„°):")
    # í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬
    video_sizes = []
    for v in videos:
        path = os.path.join("videos", v)
        size = os.path.getsize(path) / (1024*1024)
        video_sizes.append((v, size))
    
    video_sizes.sort(key=lambda x: x[1])
    
    # ì‘ì€ ì˜ìƒ 5ê°œ ì¶”ì²œ
    for i, (name, size) in enumerate(video_sizes[:5], 1):
        print(f"   {i}. {name} ({size:.1f} MB)")
    
    print("\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-5 ì¶”ì²œ, ì „ì²´ ëª©ë¡ì€ 1-50): ", end='')
    choice = input().strip()
    
    if not choice:
        choice = "1"
    
    try:
        idx = int(choice) - 1
        if idx < 5:
            selected = video_sizes[idx][0]
        else:
            selected = videos[idx]
    except:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return
    
    # ë¶„ì„ ì‹¤í–‰
    video_path = os.path.join("videos", selected)
    output_path = quick_analysis(video_path, show_preview=False)  # GUI ë¹„í™œì„±í™”
    
    print("\nğŸ‰ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. ê²°ê³¼ ì˜ìƒ í™•ì¸: output í´ë”")
    print("   2. ë¯¸ì‹ì¶•êµ¬ ì „ìš© ëª¨ë¸ í•™ìŠµ (Roboflow)")
    print("   3. íŒ€ êµ¬ë¶„ ê¸°ëŠ¥ ì¶”ê°€")
    print("   4. ë²„ë“œì•„ì´ë·° ë³€í™˜")

if __name__ == "__main__":
    main()