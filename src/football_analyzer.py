# src/football_analyzer.py
import cv2
import torch
import numpy as np
from ultralytics import YOLO
import supervision as sv
from datetime import datetime
import time
from collections import defaultdict
import pandas as pd

class FootballAnalyzer:
    def __init__(self, model_path=None, use_gpu=True):
        """
        RTX 3050 ìµœì í™” ë¯¸ì‹ì¶•êµ¬ ë¶„ì„ê¸°
        """
        # GPU ì„¤ì •
        self.device = 'cuda' if use_gpu and torch.cuda.is_available() else 'cpu'
        print(f"ğŸ® Using device: {self.device}")
        
        if self.device == 'cuda':
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # ëª¨ë¸ ë¡œë“œ
        if model_path and os.path.exists(model_path):
            print(f"ğŸ“¦ Loading custom model: {model_path}")
            self.model = YOLO(model_path)
        else:
            print("ğŸ“¦ Loading YOLOv8x model...")
            self.model = YOLO('yolov8x.pt')  # RTX 3050ì€ x ëª¨ë¸ë„ ì²˜ë¦¬ ê°€ëŠ¥
        
        # íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
        self.tracker = sv.ByteTrack(
            track_activation_threshold=0.25,
            lost_track_buffer=30,
            minimum_matching_threshold=0.8,
            frame_rate=30
        )
        
        # í•„ë“œ ê²€ì¶œê¸°
        self.field_mask = None
        
        # ì¶”ì  ë°ì´í„°
        self.tracking_data = defaultdict(list)
        
    def detect_field(self, frame):
        """ì”ë”” í•„ë“œ ì˜ì—­ ê²€ì¶œ"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # ì”ë”” ìƒ‰ìƒ ë²”ìœ„ (ì¡°ëª…ì— ë”°ë¼ ì¡°ì • í•„ìš”)
        lower_green = np.array([35, 30, 30])
        upper_green = np.array([85, 255, 255])
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = cv2.inRange(hsv, lower_green, upper_green)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((7,7), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        # ê°€ì¥ í° ì—°ê²° ì˜ì—­ ì°¾ê¸°
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest = max(contours, key=cv2.contourArea)
            mask = np.zeros_like(mask)
            cv2.fillPoly(mask, [largest], 255)
        
        self.field_mask = mask
        return mask
    
    def filter_field_objects(self, detections):
        """í•„ë“œ ë‚´ë¶€ ê°ì²´ë§Œ í•„í„°ë§"""
        if self.field_mask is None or len(detections) == 0:
            return detections
        
        filtered_indices = []
        for i, bbox in enumerate(detections.xyxy):
            x1, y1, x2, y2 = bbox
            
            # ë°”ìš´ë”© ë°•ìŠ¤ í•˜ë‹¨ ì¤‘ì•™ì  (ë°œ ìœ„ì¹˜)
            foot_x = int((x1 + x2) / 2)
            foot_y = int(y2)  # í•˜ë‹¨
            
            # í•„ë“œ ë‚´ë¶€ ì²´í¬
            if 0 <= foot_y < self.field_mask.shape[0] and \
               0 <= foot_x < self.field_mask.shape[1]:
                if self.field_mask[foot_y, foot_x] > 0:
                    filtered_indices.append(i)
        
        return detections[filtered_indices]
    
    def classify_teams(self, frame, detections):
        """íŒ€ êµ¬ë¶„ (ìœ ë‹ˆí¼ ìƒ‰ìƒ ê¸°ë°˜)"""
        if len(detections) == 0:
            return []
        
        team_colors = []
        for bbox in detections.xyxy:
            x1, y1, x2, y2 = map(int, bbox)
            
            # ìƒì²´ ì˜ì—­ ì¶”ì¶œ (ìœ ë‹ˆí¼)
            jersey_y1 = y1 + int((y2-y1) * 0.2)  # ìƒë‹¨ 20% ì œì™¸ (í—¬ë©§)
            jersey_y2 = y1 + int((y2-y1) * 0.6)  # ìƒì²´ 40%
            
            if jersey_y1 < jersey_y2 and x1 < x2:
                jersey_region = frame[jersey_y1:jersey_y2, x1:x2]
                
                # ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
                if jersey_region.size > 0:
                    avg_color = cv2.mean(jersey_region)[:3]
                    team_colors.append(avg_color)
                else:
                    team_colors.append((128, 128, 128))  # ê¸°ë³¸ íšŒìƒ‰
            else:
                team_colors.append((128, 128, 128))
        
        # K-meansë¡œ 2ê°œ íŒ€ êµ¬ë¶„ (ê°„ë‹¨í•œ ë²„ì „)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í´ëŸ¬ìŠ¤í„°ë§ í•„ìš”
        return team_colors
    
    def process_frame(self, frame, frame_id):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        # 1. ê°ì²´ ê²€ì¶œ (GPU ì‚¬ìš©)
        results = self.model(frame, device=self.device, conf=0.3, iou=0.5)
        detections = sv.Detections.from_ultralytics(results[0])
        
        # 2. í•„ë“œ ê²€ì¶œ (ì²« í”„ë ˆì„ ë˜ëŠ” ì£¼ê¸°ì )
        if frame_id == 0 or frame_id % 100 == 0:
            self.detect_field(frame)
        
        # 3. í•„ë“œ ë‚´ë¶€ ê°ì²´ë§Œ í•„í„°ë§
        field_detections = self.filter_field_objects(detections)
        
        # 4. ê°ì²´ ì¶”ì 
        tracked_detections = self.tracker.update_with_detections(field_detections)
        
        # 5. íŒ€ ë¶„ë¥˜
        team_colors = self.classify_teams(frame, tracked_detections)
        
        # 6. ë°ì´í„° ì €ì¥
        for i, (bbox, track_id) in enumerate(zip(tracked_detections.xyxy, tracked_detections.tracker_id)):
            x1, y1, x2, y2 = bbox
            self.tracking_data[track_id].append({
                'frame': frame_id,
                'bbox': [float(x1), float(y1), float(x2), float(y2)],
                'center': [float((x1+x2)/2), float((y1+y2)/2)],
                'team_color': team_colors[i] if i < len(team_colors) else None
            })
        
        return tracked_detections, team_colors
    
    def visualize_frame(self, frame, detections, team_colors, frame_id):
        """í”„ë ˆì„ ì‹œê°í™”"""
        annotated = frame.copy()
        
        # í•„ë“œ ì˜ì—­ ì˜¤ë²„ë ˆì´
        if self.field_mask is not None:
            field_overlay = np.zeros_like(frame)
            field_overlay[:,:,1] = self.field_mask // 4  # ë…¹ìƒ‰ ë°˜íˆ¬ëª…
            annotated = cv2.addWeighted(annotated, 0.85, field_overlay, 0.15, 0)
        
        # ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°
        if len(detections) > 0:
            # ê²½ê³„ ìƒì ë° ID
            labels = [f"ID:{tid}" for tid in detections.tracker_id]
            annotated = sv.BoundingBoxAnnotator().annotate(annotated, detections)
            annotated = sv.LabelAnnotator().annotate(annotated, detections, labels)
            
            # ì¶”ì  ê²½ë¡œ
            for track_id in self.tracking_data:
                points = []
                for data in self.tracking_data[track_id][-30:]:  # ìµœê·¼ 30í”„ë ˆì„
                    if data['frame'] <= frame_id:
                        points.append(data['center'])
                
                if len(points) > 1:
                    points = np.array(points, dtype=np.int32)
                    cv2.polylines(annotated, [points], False, (0, 255, 0), 2)
        
        # ì •ë³´ í‘œì‹œ
        info_text = [
            f"Frame: {frame_id}",
            f"Detected: {len(detections)}",
            f"FPS: {self.fps:.1f}" if hasattr(self, 'fps') else "FPS: --"
        ]
        
        for i, text in enumerate(info_text):
            cv2.putText(annotated, text, (10, 30 + i*30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        return annotated

class VideoProcessor:
    def __init__(self, analyzer):
        self.analyzer = analyzer
        
    def process_video(self, input_path, output_path=None, show_preview=False):
        """ë¹„ë””ì˜¤ ì „ì²´ ì²˜ë¦¬"""
        print(f"\nğŸ“¹ Processing video: {input_path}")
        
        # ë¹„ë””ì˜¤ ì—´ê¸°
        cap = cv2.VideoCapture(input_path)
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"   Resolution: {width}x{height}")
        print(f"   FPS: {fps}")
        print(f"   Total frames: {total_frames}")
        
        # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
        out = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        # ì²˜ë¦¬ ì‹œì‘
        frame_id = 0
        start_time = time.time()
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # í”„ë ˆì„ ì²˜ë¦¬
                frame_start = time.time()
                detections, team_colors = self.analyzer.process_frame(frame, frame_id)
                
                # FPS ê³„ì‚°
                self.analyzer.fps = 1 / (time.time() - frame_start)
                
                # ì‹œê°í™”
                annotated = self.analyzer.visualize_frame(frame, detections, team_colors, frame_id)
                
                # ì €ì¥
                if out:
                    out.write(annotated)
                
                # ë¯¸ë¦¬ë³´ê¸°
                if show_preview:
                    cv2.imshow('Football Analysis', cv2.resize(annotated, (1280, 720)))
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                
                # ì§„í–‰ ìƒí™©
                frame_id += 1
                if frame_id % 30 == 0:
                    elapsed = time.time() - start_time
                    eta = (elapsed / frame_id) * (total_frames - frame_id)
                    print(f"   Progress: {frame_id}/{total_frames} ({frame_id/total_frames*100:.1f}%) - ETA: {eta:.0f}s")
        
        finally:
            cap.release()
            if out:
                out.release()
            cv2.destroyAllWindows()
        
        # ì™„ë£Œ
        total_time = time.time() - start_time
        print(f"\nâœ… Processing complete!")
        print(f"   Time: {total_time:.1f}s")
        print(f"   Avg FPS: {frame_id/total_time:.1f}")
        print(f"   Tracked objects: {len(self.analyzer.tracking_data)}")
        
        return self.analyzer.tracking_data

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    import os
    
    # ê²½ë¡œ ì„¤ì •
    base_dir = r"C:\Users\ê²½ì“°ë¶\Desktop\Stech\football-tracking"
    input_video = os.path.join(base_dir, "videos", "sample.mp4")  # ì—¬ê¸°ì— ì˜ìƒ íŒŒì¼ëª…
    output_video = os.path.join(base_dir, "output", f"analyzed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    print("ğŸˆ Initializing Football Analyzer...")
    analyzer = FootballAnalyzer(use_gpu=True)
    
    # ë¹„ë””ì˜¤ ì²˜ë¦¬
    processor = VideoProcessor(analyzer)
    tracking_data = processor.process_video(
        input_video, 
        output_video,
        show_preview=True  # ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸°
    )
    
    # ê²°ê³¼ ì €ì¥
    save_results(tracking_data, base_dir)

def save_results(tracking_data, base_dir):
    """ì¶”ì  ê²°ê³¼ ì €ì¥"""
    # DataFrame ìƒì„±
    rows = []
    for track_id, frames in tracking_data.items():
        for frame_data in frames:
            rows.append({
                'track_id': track_id,
                'frame': frame_data['frame'],
                'x1': frame_data['bbox'][0],
                'y1': frame_data['bbox'][1],
                'x2': frame_data['bbox'][2],
                'y2': frame_data['bbox'][3],
                'center_x': frame_data['center'][0],
                'center_y': frame_data['center'][1]
            })
    
    df = pd.DataFrame(rows)
    
    # CSV ì €ì¥
    output_file = os.path.join(base_dir, "output", f"tracking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    df.to_csv(output_file, index=False)
    print(f"ğŸ“Š Tracking data saved: {output_file}")
    
    # í†µê³„ ì¶œë ¥
    print("\nğŸ“ˆ Statistics:")
    print(f"   Total tracks: {df['track_id'].nunique()}")
    print(f"   Total detections: {len(df)}")
    print(f"   Avg track length: {len(df) / df['track_id'].nunique():.1f} frames")

if __name__ == "__main__":
    main()